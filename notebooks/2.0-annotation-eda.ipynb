{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_based_annot_path_dev = \"../bipolar_eeg_dataset/train_channel_based_annotation.json\"\n",
    "term_based_annot_path_dev = \"../bipolar_eeg_dataset/trian_term_based_annotation.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `channel-based` annotation to a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(channel_based_annot_path_dev,\"r\") as channel_json:\n",
    "    channel_annotation= json.load(channel_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_window(eeg_sample,channel_annot,s_freq,w=20):\n",
    "    context_length = w * s_freq\n",
    "    sample_length = eeg_sample.shape[-1]\n",
    "\n",
    "    padding_size = int(context_length * torch.ceil(torch.tensor(sample_length/context_length)).item())\n",
    "\n",
    "    padded_zero = torch.zeros(eeg_sample.shape[0],padding_size)\n",
    "\n",
    "    padded_zero[...,0:sample_length] = eeg_sample\n",
    "\n",
    "    padded_zero = padded_zero.view(-1,padded_zero.shape[0],context_length)\n",
    "\n",
    "\n",
    "    target = torch.zeros(padded_zero.shape[0],padded_zero.shape[1])\n",
    "\n",
    "    for idx in range(target.shape[0]):\n",
    "        channel_labels_tensor = torch.zeros(target.shape[1])\n",
    "        channel_labels = []\n",
    "\n",
    "        for i,(channel,labels) in enumerate(channel_annot.items()):\n",
    "            for label in labels:\n",
    "                start_time,stop_time,c = label\n",
    "\n",
    "                sample_start_time = idx * w\n",
    "                sample_stop_time = (idx + 1) * w\n",
    "                if sample_start_time >= start_time and sample_stop_time <= stop_time:\n",
    "\n",
    "                    channel_labels.append(0 if c ==\"bckg\" else 1)\n",
    "        channel_labels_tensor[0:len(channel_labels)] = torch.tensor(channel_labels,dtype=torch.float32)\n",
    "\n",
    "        target[idx,...] =channel_labels_tensor\n",
    "    return padded_zero,target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_load(annotation,new_s_freq = 256,window=20,batch_size=4):\n",
    "    default_channel_nums = 22\n",
    "    sample_freq = annotation[\"s_freq\"]  # sampleing freqeuncy\n",
    "    montage = annotation[\"montage\"]\n",
    "\n",
    "\n",
    "    resampler = torchaudio.transforms.Resample(sample_freq,new_s_freq)\n",
    "\n",
    "    with np.load(annotation[\"npz_filepath\"]) as npz_file:\n",
    "        raw_eeg = npz_file[\"arr_0\"]\n",
    "\n",
    "    raw_eeg = torch.from_numpy(raw_eeg).to(torch.float32)\n",
    "    # resample\n",
    "    raw_eeg_resample = resampler(raw_eeg)\n",
    "\n",
    "    if montage not in [\"01_tcp_ar\",\"02_tcp_le\"]:\n",
    "        zero_eeg = torch.zeros(default_channel_nums,raw_eeg_resample.shape[-1])\n",
    "        zero_eeg[0:raw_eeg_resample.shape[0],...] = raw_eeg_resample\n",
    "\n",
    "        raw_eeg_resample = zero_eeg\n",
    "\n",
    "    x,y =  create_window(raw_eeg_resample,annotation[\"channel_annot\"],new_s_freq,window)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "    #return get_batch(x,y,batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter reading with only `bckg` annotation for the whole sample duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4599/4599 [10:26<00:00,  7.34it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_annotations = []\n",
    "for annots in tqdm(channel_annotation,total=len(channel_annotation)):\n",
    "    x,y = sample_and_load(annots)\n",
    "    if y.sum() > 0:\n",
    "        filtered_annotations.append(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial num. of EEG readings = 4599\n",
      "EEG readings after filtering = 723\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial num. of EEG readings = {len(channel_annotation)}\")\n",
    "print(f\"EEG readings after filtering = {len(filtered_annotations)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the total EEG reading duration in the filtered dataset. In `minutes` or `hours`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_reading_duration_per_class(channel_annotation,cond=None):\n",
    "   duration_for_all = []\n",
    "   for annots in channel_annotation:\n",
    "      durations = []\n",
    "      for channel_values in annots[\"channel_annot\"].values():\n",
    "         ch_values = []\n",
    "         for v in channel_values:\n",
    "            if v[-1] == cond:\n",
    "               ch_values.append(v[1])   \n",
    "\n",
    "         if len(ch_values) == 0:\n",
    "            durations.append(0)\n",
    "\n",
    "         if len(ch_values) == 1:\n",
    "            durations.append(ch_values[0])\n",
    "\n",
    "         if len(ch_values) > 2:\n",
    "            ch_values = sorted(ch_values)\n",
    "            s = ch_values[0]\n",
    "\n",
    "            for _ in ch_values:\n",
    "               s += ch_values[1] - ch_values[0]\n",
    "               ch_values = ch_values[1:]\n",
    "               if len(ch_values) < 2:\n",
    "                  break\n",
    "            durations.append(s)\n",
    "\n",
    "      if len(durations) == 0:\n",
    "         duration_for_all.append(0)\n",
    "      else:      \n",
    "         duration_for_all.append(sum(durations)/len(durations))\n",
    "      \n",
    "   return sum(duration_for_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {0: '(null)', 1: 'spsw', 2: 'gped', 3: 'pled', 4: 'eyem', 5: 'artf', 6: 'bckg', 7: 'seiz', 8: 'fnsz', 9: 'gnsz', 10: 'spsz', 11: 'cpsz', 12: 'absz', 13: 'tnsz', 14: 'cnsz', 15: 'tcsz', 16: 'atsz', 17: 'mysz', 18: 'nesz', 19: 'intr', 20: 'slow', 21: 'eyem', 22: 'chew', 23: 'shiv', 24: 'musc', 25: 'elpp', 26: 'elst', 27: 'calb'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EEG duration for `bckg` = ~ 139.106 hours\n",
      "Training EEG duration for `fnsz` = ~ 19.317 hours\n",
      "Training EEG duration for `gnsz` = ~ 15.241 hours\n",
      "Training EEG duration for `spsz` = ~ 1.004 hours\n",
      "Training EEG duration for `cpsz` = ~ 8.434 hours\n",
      "Training EEG duration for `tnsz` = ~ 0.718 hours\n",
      "Training EEG duration for `tcsz` = ~ 1.466 hours\n",
      "Training EEG duration for `mysz` = ~ 0.362 hours\n",
      "Total Training EEG duration = ~ 185.649 hours\n"
     ]
    }
   ],
   "source": [
    "total_hours = 0\n",
    "for class_name in class_dict.values(): \n",
    "# of those how many hours are the background class\n",
    "  hours = total_reading_duration_per_class(filtered_annotations,class_name) / 3600\n",
    "  total_hours += hours\n",
    "  if hours == 0.:\n",
    "    continue\n",
    "  print(f\"Training EEG duration for `{class_name}` = ~ {hours :.3f} hours\")\n",
    "\n",
    "print(f\"Total Training EEG duration = ~ {total_hours:.3f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write filtered annotations to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../bipolar_eeg_dataset/dev_filtred_channel_based.json\",\"w\") as f:\n",
    "    json.dump(filtered_annotations,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
